{
 "cells": [
  {
<<<<<<< HEAD
   "cell_type": "raw",
   "id": "cfe0c000",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Installing Required Packages\n",
    "To get started, make sure you have the necessary packages installed"
   ]
  },
  {
=======
>>>>>>> 78a7bbd6e9b037770c0fc3f0a894df68e2602140
   "cell_type": "code",
   "execution_count": null,
   "id": "67d6c379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index\n",
      "  Using cached llama_index-0.12.34-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting llama-index-agent-openai<0.5,>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_agent_openai-0.4.7-py3-none-any.whl.metadata (438 bytes)\n",
      "Collecting llama-index-cli<0.5,>=0.4.1 (from llama-index)\n",
      "  Using cached llama_index_cli-0.4.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: llama-index-core<0.13,>=0.12.34 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index) (0.12.34.post1)\n",
      "Collecting llama-index-embeddings-openai<0.4,>=0.3.0 (from llama-index)\n",
      "  Using cached llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata (684 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index)\n",
      "  Using cached llama_index_indices_managed_llama_cloud-0.6.11-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting llama-index-llms-openai<0.4,>=0.3.0 (from llama-index)\n",
      "  Using cached llama_index_llms_openai-0.3.38-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.5,>=0.4.0 (from llama-index)\n",
      "  Using cached llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl.metadata (726 bytes)\n",
      "Collecting llama-index-program-openai<0.4,>=0.3.0 (from llama-index)\n",
      "  Using cached llama_index_program_openai-0.3.1-py3-none-any.whl.metadata (764 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.4,>=0.3.0 (from llama-index)\n",
      "  Using cached llama_index_question_gen_openai-0.3.0-py3-none-any.whl.metadata (783 bytes)\n",
      "Collecting llama-index-readers-file<0.5,>=0.4.0 (from llama-index)\n",
      "  Using cached llama_index_readers_file-0.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index)\n",
      "  Using cached llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index) (3.9.1)\n",
      "Requirement already satisfied: openai>=1.14.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.77.0)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (3.11.18)\n",
      "Requirement already satisfied: banks<3,>=2.0.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (2.1.2)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (1.0.8)\n",
      "Requirement already satisfied: eval-type-backport<0.3,>=0.2.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (0.2.2)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (2025.3.2)\n",
      "Requirement already satisfied: httpx in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (3.2.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (2.0.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (11.2.1)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (2.11.4)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (2.32.3)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.34->llama-index) (2.0.40)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (4.13.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (1.17.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.34->llama-index) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.34->llama-index) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.34->llama-index) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.34->llama-index) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.34->llama-index) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.34->llama-index) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.34->llama-index) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.34->llama-index) (1.20.0)\n",
      "Requirement already satisfied: griffe in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.34->llama-index) (1.7.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.34->llama-index) (3.1.6)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.34->llama-index) (4.3.7)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (4.13.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (2.2.3)\n",
      "Collecting pypdf<6.0.0,>=5.1.0 (from llama-index-readers-file<0.5,>=0.4.0->llama-index)\n",
      "  Using cached pypdf-5.4.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.5,>=0.4.0->llama-index)\n",
      "  Using cached striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2.7)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (0.9.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from httpx->llama-index-core<0.13,>=0.12.34->llama-index) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from httpx->llama-index-core<0.13,>=0.12.34->llama-index) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.13,>=0.12.34->llama-index) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.34->llama-index) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.34->llama-index) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.34->llama-index) (0.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from tqdm<5,>=4.66.1->llama-index-core<0.13,>=0.12.34->llama-index) (0.4.6)\n",
      "Collecting llama-cloud<0.2.0,>=0.1.13 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index)\n",
      "  Using cached llama_cloud-0.1.19-py3-none-any.whl.metadata (902 bytes)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.21-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting llama-cloud-services>=0.6.21 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.21-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-cloud-services>=0.6.21->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (8.1.8)\n",
      "Collecting python-dotenv<2.0.0,>=1.0.1 (from llama-cloud-services>=0.6.21->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: joblib in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from nltk>3.8.1->llama-index) (1.5.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.34->llama-index) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.34->llama-index) (2.4.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.34->llama-index) (3.2.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13,>=0.12.34->llama-index) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from dataclasses-json->llama-index-core<0.13,>=0.12.34->llama-index) (3.26.1)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13,>=0.12.34->llama-index) (24.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.34->llama-index) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from pandas->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from pandas->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from pandas->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5,>=0.4.0->llama-index) (1.17.0)\n",
      "Using cached llama_index-0.12.34-py3-none-any.whl (7.0 kB)\n",
      "Downloading llama_index_agent_openai-0.4.7-py3-none-any.whl (14 kB)\n",
      "Using cached llama_index_cli-0.4.1-py3-none-any.whl (28 kB)\n",
      "Using cached llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\n",
      "Using cached llama_index_llms_openai-0.3.38-py3-none-any.whl (23 kB)\n",
      "Using cached llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl (5.9 kB)\n",
      "Using cached llama_index_program_openai-0.3.1-py3-none-any.whl (5.3 kB)\n",
      "Using cached llama_index_question_gen_openai-0.3.0-py3-none-any.whl (2.9 kB)\n",
      "Using cached llama_index_readers_file-0.4.7-py3-none-any.whl (40 kB)\n",
      "Using cached pypdf-5.4.0-py3-none-any.whl (302 kB)\n",
      "Using cached striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Using cached llama_index_indices_managed_llama_cloud-0.6.11-py3-none-any.whl (14 kB)\n",
      "Using cached llama_cloud-0.1.19-py3-none-any.whl (263 kB)\n",
      "Using cached llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\n",
      "Downloading llama_parse-0.6.21-py3-none-any.whl (4.9 kB)\n",
      "Downloading llama_cloud_services-0.6.21-py3-none-any.whl (37 kB)\n",
      "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: striprtf, python-dotenv, pypdf, llama-cloud, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-cloud-services, llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-readers-llama-parse, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
      "\n",
      "   -- -------------------------------------  1/17 [python-dotenv]\n",
      "   -- -------------------------------------  1/17 [python-dotenv]\n",
      "   ---- -----------------------------------  2/17 [pypdf]\n",
      "   ---- -----------------------------------  2/17 [pypdf]\n",
      "   ---- -----------------------------------  2/17 [pypdf]\n",
      "   ---- -----------------------------------  2/17 [pypdf]\n",
      "   ---- -----------------------------------  2/17 [pypdf]\n",
      "   ---- -----------------------------------  2/17 [pypdf]\n",
      "   ---- -----------------------------------  2/17 [pypdf]\n",
      "   ------- --------------------------------  3/17 [llama-cloud]\n",
      "   ------- --------------------------------  3/17 [llama-cloud]\n",
      "   ------- --------------------------------  3/17 [llama-cloud]\n",
      "   ------- --------------------------------  3/17 [llama-cloud]\n",
      "   ------- --------------------------------  3/17 [llama-cloud]\n",
      "   ------- --------------------------------  3/17 [llama-cloud]\n",
      "   ------- --------------------------------  3/17 [llama-cloud]\n",
      "   ------- --------------------------------  3/17 [llama-cloud]\n",
      "   ------- --------------------------------  3/17 [llama-cloud]\n",
      "   ------- --------------------------------  3/17 [llama-cloud]\n",
      "   ------- --------------------------------  3/17 [llama-cloud]\n",
      "   ------- --------------------------------  3/17 [llama-cloud]\n",
      "   ------- --------------------------------  3/17 [llama-cloud]\n",
      "   ------- --------------------------------  3/17 [llama-cloud]\n",
      "   ------- --------------------------------  3/17 [llama-cloud]\n",
      "   ------- --------------------------------  3/17 [llama-cloud]\n",
      "   ------- --------------------------------  3/17 [llama-cloud]\n",
      "   ------- --------------------------------  3/17 [llama-cloud]\n",
      "   ------- --------------------------------  3/17 [llama-cloud]\n",
      "   ------- --------------------------------  3/17 [llama-cloud]\n",
      "   ------- --------------------------------  3/17 [llama-cloud]\n",
      "   ------- --------------------------------  3/17 [llama-cloud]\n",
      "   --------- ------------------------------  4/17 [llama-index-readers-file]\n",
      "   --------- ------------------------------  4/17 [llama-index-readers-file]\n",
      "   --------- ------------------------------  4/17 [llama-index-readers-file]\n",
      "   --------- ------------------  6/17 [llama-index-indices-managed-llama-cloud]\n",
      "   ------------------ ---------------------  8/17 [llama-cloud-services]\n",
      "   --------------------- ------------------  9/17 [llama-parse]\n",
      "   ------------------------- -------------- 11/17 [llama-index-cli]\n",
      "   ---------------------------- ----------- 12/17 [llama-index-agent-openai]\n",
      "   ------------------------------- ---- 15/17 [llama-index-question-gen-openai]\n",
      "   ---------------------------------------- 17/17 [llama-index]\n",
      "\n",
      "Successfully installed llama-cloud-0.1.19 llama-cloud-services-0.6.21 llama-index-0.12.34 llama-index-agent-openai-0.4.7 llama-index-cli-0.4.1 llama-index-embeddings-openai-0.3.1 llama-index-indices-managed-llama-cloud-0.6.11 llama-index-llms-openai-0.3.38 llama-index-multi-modal-llms-openai-0.4.3 llama-index-program-openai-0.3.1 llama-index-question-gen-openai-0.3.0 llama-index-readers-file-0.4.7 llama-index-readers-llama-parse-0.4.0 llama-parse-0.6.21 pypdf-5.4.0 python-dotenv-1.1.0 striprtf-0.0.26\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e7456c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-llms-groq\n",
      "  Using cached llama_index_llms_groq-0.3.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-llms-groq) (0.12.34.post1)\n",
      "Collecting llama-index-llms-openai-like<0.4.0,>=0.3.1 (from llama-index-llms-groq)\n",
      "  Using cached llama_index_llms_openai_like-0.3.4-py3-none-any.whl.metadata (751 bytes)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (3.11.18)\n",
      "Requirement already satisfied: banks<3,>=2.0.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (2.1.2)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (1.0.8)\n",
      "Requirement already satisfied: eval-type-backport<0.3,>=0.2.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (0.2.2)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (2025.3.2)\n",
      "Requirement already satisfied: httpx in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (3.2.1)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (2.0.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (11.2.1)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (2.11.4)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (2.32.3)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (2.0.40)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (4.13.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (1.17.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (1.20.0)\n",
      "Requirement already satisfied: griffe in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (1.7.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (3.1.6)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (4.3.7)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.9 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-groq) (0.3.38)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.37.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-groq) (4.51.3)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.66.3 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-llms-openai<0.4.0,>=0.3.9->llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-groq) (1.77.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from openai<2.0.0,>=1.66.3->llama-index-llms-openai<0.4.0,>=0.3.9->llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-groq) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from openai<2.0.0,>=1.66.3->llama-index-llms-openai<0.4.0,>=0.3.9->llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-groq) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from openai<2.0.0,>=1.66.3->llama-index-llms-openai<0.4.0,>=0.3.9->llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-groq) (0.9.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from openai<2.0.0,>=1.66.3->llama-index-llms-openai<0.4.0,>=0.3.9->llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-groq) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.66.3->llama-index-llms-openai<0.4.0,>=0.3.9->llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-groq) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.66.3->llama-index-llms-openai<0.4.0,>=0.3.9->llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-groq) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (0.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from tqdm<5,>=4.66.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (0.4.6)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-groq) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-groq) (0.30.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-groq) (24.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-groq) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-groq) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.4.0,>=0.3.1->llama-index-llms-groq) (0.5.3)\n",
      "Requirement already satisfied: click in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (1.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (2.4.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (3.2.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (3.26.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-groq) (3.0.2)\n",
      "Using cached llama_index_llms_groq-0.3.1-py3-none-any.whl (2.9 kB)\n",
      "Using cached llama_index_llms_openai_like-0.3.4-py3-none-any.whl (4.3 kB)\n",
      "Installing collected packages: llama-index-llms-openai-like, llama-index-llms-groq\n",
      "\n",
      "   -------------------- ------------------- 1/2 [llama-index-llms-groq]\n",
      "   ---------------------------------------- 2/2 [llama-index-llms-groq]\n",
      "\n",
      "Successfully installed llama-index-llms-groq-0.3.1 llama-index-llms-openai-like-0.3.4\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index-llms-groq"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "raw",
   "id": "05224c75",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Make sure you have your API key ready. Go to Groq and create an API_KEY, then replace \"GROQ_API_KEY\" in the code below."
   ]
  },
  {
=======
>>>>>>> 78a7bbd6e9b037770c0fc3f0a894df68e2602140
   "cell_type": "code",
   "execution_count": null,
   "id": "76501eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\envs\\llama_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.groq import Groq\n",
    "llm = Groq(model=\"deepseek-r1-distill-llama-70b\", api_key=\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45e7125c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "raw",
   "id": "65cdb8d6",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Import SimpleDirectoryReader and add the file you want to use"
   ]
  },
  {
=======
>>>>>>> 78a7bbd6e9b037770c0fc3f0a894df68e2602140
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e359d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "# load documents\n",
    "documents = SimpleDirectoryReader(input_files=[\"metagpt.pdf\"]).load_data()"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "raw",
   "id": "e492f010",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Import SentenceSplitter to break your documents into smaller, more manageable pieces"
   ]
  },
  {
=======
>>>>>>> 78a7bbd6e9b037770c0fc3f0a894df68e2602140
   "cell_type": "code",
   "execution_count": 4,
   "id": "d13a84ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "splitter = SentenceSplitter(chunk_size=1024)\n",
    "nodes = splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "raw",
   "id": "11eaf879",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "To use Hugging Face models with LlamaIndex, make sure you have the necessary connectors installed"
   ]
  },
  {
=======
>>>>>>> 78a7bbd6e9b037770c0fc3f0a894df68e2602140
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfb0ff1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-llms-huggingface in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (0.5.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-llms-huggingface) (0.12.34.post1)\n",
      "Requirement already satisfied: torch<3.0.0,>=2.1.2 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-llms-huggingface) (2.7.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.37.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (4.51.3)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (3.11.18)\n",
      "Requirement already satisfied: banks<3,>=2.0.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (2.1.2)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.0.8)\n",
      "Requirement already satisfied: eval-type-backport<0.3,>=0.2.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (0.2.2)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (2025.3.2)\n",
      "Requirement already satisfied: httpx in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (3.2.1)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (2.0.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (11.2.1)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (2.11.4)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (2.32.3)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (2.0.40)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (4.13.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.17.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.20.0)\n",
      "Requirement already satisfied: griffe in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.7.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (3.1.6)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (4.3.7)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (3.18.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (1.14.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from tqdm<5,>=4.66.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (0.4.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (0.30.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (24.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (0.5.3)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (1.6.0)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (3.10)\n",
      "Requirement already satisfied: psutil in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from accelerate>=0.26.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (7.0.0)\n",
      "Requirement already satisfied: click in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.5.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (2025.4.26)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (3.2.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from sympy>=1.13.3->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (1.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (3.26.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (0.16.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface) (3.0.2)\n",
      "Requirement already satisfied: llama-index-llms-huggingface-api in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (0.4.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-llms-huggingface-api) (0.30.2)\n",
      "Requirement already satisfied: llama-index-core<0.13,>=0.12.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-llms-huggingface-api) (0.12.34.post1)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (3.11.18)\n",
      "Requirement already satisfied: banks<3,>=2.0.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (2.1.2)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (1.0.8)\n",
      "Requirement already satisfied: eval-type-backport<0.3,>=0.2.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (0.2.2)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (2025.3.2)\n",
      "Requirement already satisfied: httpx in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (3.2.1)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (2.0.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (11.2.1)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (2.11.4)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (2.32.3)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (2.0.40)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (4.13.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (1.17.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (1.20.0)\n",
      "Requirement already satisfied: griffe in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (1.7.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (3.1.6)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (4.3.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from tqdm<5,>=4.66.1->llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (0.4.6)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (3.10)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from huggingface-hub>=0.23.0->llama-index-llms-huggingface-api) (3.18.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from huggingface-hub>=0.23.0->llama-index-llms-huggingface-api) (24.2)\n",
      "Requirement already satisfied: click in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (1.5.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (2025.4.26)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (3.2.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from dataclasses-json->llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (3.26.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from httpx->llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from httpx->llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (0.16.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from anyio->httpx->llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from anyio->httpx->llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\anaconda3\\envs\\llama_env\\lib\\site-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-llms-huggingface-api) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index-llms-huggingface\n",
    "%pip install llama-index-llms-huggingface-api"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "raw",
   "id": "21bcbeea",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Import the required modules and specify the Hugging Face model you want to use for embeddings"
   ]
  },
  {
=======
>>>>>>> 78a7bbd6e9b037770c0fc3f0a894df68e2602140
   "cell_type": "code",
   "execution_count": 5,
   "id": "d78b8a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "model_name = \"intfloat/multilingual-e5-large\"\n",
    "# local_model_path = os.path.join(os.getcwd(), \"embedding_models\", \"multilingual-e5-large\")\n",
    "embedded_model = HuggingFaceEmbedding(model_name=model_name)"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "raw",
   "id": "b58aba22",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Import the necessary modules and set up your LLM and embedding model"
   ]
  },
  {
=======
>>>>>>> 78a7bbd6e9b037770c0fc3f0a894df68e2602140
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b66be0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.groq import Groq\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embedded_model"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "raw",
   "id": "7b87e528",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Create a SummaryIndex for concise summaries and a VectorStoreIndex for semantic search, both based on the processed document nodes"
   ]
  },
  {
=======
>>>>>>> 78a7bbd6e9b037770c0fc3f0a894df68e2602140
   "cell_type": "code",
   "execution_count": 7,
   "id": "910696a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SummaryIndex, VectorStoreIndex\n",
    "\n",
    "summary_index = SummaryIndex(nodes, llm=llm)\n",
    "vector_index = VectorStoreIndex(nodes, embed_model=embedded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d52e966d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_query_engine = summary_index.as_query_engine(\n",
    "    llm = llm,\n",
    "    response_mode=\"tree_summarize\",\n",
    "    use_async=True,\n",
    ")\n",
    "vector_query_engine = vector_index.as_query_engine()"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "raw",
   "id": "d2abf67c",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Set up tools to handle different types of questions – one for summarization and one for precise context retrieval"
   ]
  },
  {
=======
>>>>>>> 78a7bbd6e9b037770c0fc3f0a894df68e2602140
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1a04bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "\n",
    "summary_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=summary_query_engine,\n",
    "    description=(\n",
    "        \"Useful for summarization questions related to MetaGPT\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "vector_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=vector_query_engine,\n",
    "    description=(\n",
    "        \"Useful for retrieving specific context from the MetaGPT paper.\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "raw",
   "id": "a3a3da5b",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Combine your query tools with a router engine to intelligently direct incoming questions based on their nature"
   ]
  },
  {
=======
>>>>>>> 78a7bbd6e9b037770c0fc3f0a894df68e2602140
   "cell_type": "code",
   "execution_count": 11,
   "id": "eac8f548",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine.router_query_engine import RouterQueryEngine\n",
    "from llama_index.core.selectors import LLMSingleSelector\n",
    "\n",
    "\n",
    "query_engine = RouterQueryEngine(\n",
    "    selector=LLMSingleSelector.from_defaults(),\n",
    "    query_engine_tools=[\n",
    "        summary_tool,\n",
    "        vector_tool,\n",
    "    ],\n",
    "    llm=llm,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20020855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 0: The question asks for a summary of the document, which is directly related to summarization questions..\n",
      "\u001b[0m<think>\n",
      "Okay, I need to summarize the document based on the provided context. Let me go through each section to understand the key points.\n",
      "\n",
      "The document starts by discussing the operating procedures of a software company, emphasizing role specialization. It defines five roles: Product Manager, Architect, Project Manager, Engineer, and QA Engineer. Each role has specific responsibilities and skills, contributing to the software development process in a structured way. They use SOPs (Standard Operating Procedures) to ensure sequential workflow, which is crucial for collaboration.\n",
      "\n",
      "Next, the communication protocol is detailed. The document critiques the use of natural language in multi-agent systems, citing issues like information distortion. Instead, they propose structured communication with predefined schemas and formats. This approach ensures that each role provides necessary outputs without irrelevant information. They also introduce a publish-subscribe mechanism using a shared message pool, allowing agents to access only relevant information based on their roles, thus enhancing efficiency.\n",
      "\n",
      "The iterative programming section talks about an executable feedback mechanism. After initial code generation, the Engineer tests the code using unit tests. If the tests fail, the Engineer debugs and retries up to three times. This iterative process aims to improve code quality and correctness, addressing issues like LLM hallucinations.\n",
      "\n",
      "The experiments section evaluates MetaGPT against other models using benchmarks like HumanEval, MBPP, and a custom SoftwareDev dataset. They use metrics such as Pass@k, executability, cost, code statistics, productivity, and human revision cost. The results show that MetaGPT outperforms other models in both functional accuracy and practical aspects, with high executability scores and lower human revision costs.\n",
      "\n",
      "The capabilities analysis highlights MetaGPT's advantages over other frameworks, emphasizing its structured approach, role-based management, and comprehensive features like PRD generation and precompilation execution. The ablation study further supports the importance of these structured elements.\n",
      "\n",
      "Putting it all together, the document presents MetaGPT as a multi-agent framework that leverages structured communication, SOPs, and iterative feedback to enhance software development tasks, demonstrating superior performance in various benchmarks.\n",
      "</think>\n",
      "\n",
      "The document introduces MetaGPT, a multi-agent framework designed to enhance software development through structured communication, standard operating procedures (SOPs), and iterative feedback mechanisms. It defines five specialized roles—Product Manager, Architect, Project Manager, Engineer, and QA Engineer—each contributing specific skills and outputs to the development process. MetaGPT employs structured communication protocols to prevent information distortion, using a shared message pool with a publish-subscribe mechanism for efficient information exchange. \n",
      "\n",
      "The framework incorporates an iterative programming approach where engineers test and debug code, improving quality through executable feedback. Experimental results show MetaGPT outperforming other models on benchmarks like HumanEval, MBPP, and a custom SoftwareDev dataset, demonstrating high executability and reduced human revision costs. The document concludes by highlighting MetaGPT's advanced capabilities in handling complex software tasks, emphasizing the benefits of its structured and collaborative approach.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What is the summary of the document?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8cdd56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 1: The question asks for specific details on how agents share information, which is best retrieved from the MetaGPT paper..\n",
      "\u001b[0m<think>\n",
      "Okay, so I need to figure out how agents share information with each other based on the provided context. Let me read through the context carefully.\n",
      "\n",
      "From page 6, it mentions that agents use a global message pool to exchange messages. This means that instead of one-to-one communication, which can get complicated, all agents can publish their messages in this shared pool. So, any agent can access the pool and retrieve the information they need without having to ask each agent individually. That makes communication more efficient.\n",
      "\n",
      "Also, there's a subscription mechanism. Agents don't get overwhelmed with all the information because they can subscribe based on their roles. They only receive the information relevant to their tasks. For example, the Architect focuses on PRDs from the Product Manager and doesn't get distracted by other roles' documents.\n",
      "\n",
      "So, putting it together, agents share information by publishing to a shared pool and subscribing to only what's relevant, which helps manage information overload and keeps communication efficient.\n",
      "</think>\n",
      "\n",
      "Agents share information through a global message pool where they publish their structured messages. They use a subscription mechanism to access only the information relevant to their roles, enhancing efficiency and reducing overload.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"How do agents share information with other agents?\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f7eee49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(response.source_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1af39844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=TextNode(id_='b207f754-5224-44c7-92a2-6074be2eb0c9', embedding=None, metadata={'page_label': '6', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2025-04-30', 'last_modified_date': '2025-04-30'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='f175015c-a7d6-4baa-b53c-7daa56523bb4', node_type='4', metadata={'page_label': '6', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2025-04-30', 'last_modified_date': '2025-04-30'}, hash='aa1d21781adc058bdded8dbe3fe8cd6024c645c8d03b1cbb7b6e4dd12568d053')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Preprint\\nwhispers)2, after several rounds of communication, the original information may be quite distorted.\\nInspired by human social structures, we propose using structured communication to formulate the\\ncommunication of agents. We establish a schema and format for each role and request that individ-\\nuals provide the necessary outputs based on their specific role and context.\\nAs shown in Figure 3, the Architect agent generates two outputs: the system interface design and a\\nsequence flow diagram. These contain system module design and interaction sequences, which serve\\nas important deliverables for Engineers. Unlike ChatDev (Zhao et al., 2023), agents in MetaGPT\\ncommunicate through documents and diagrams (structured outputs) rather than dialogue. These\\ndocuments contain all necessary information, preventing irrelevant or missing content.\\nPublish-Subscribe Mechanism Sharing information is critical in collaboration. For instance,\\nArchitects and Engineers often need to reference PRDs. However, communicating this information\\neach time in a one-to-one manner, as indicated by previous work (Li et al., 2023; Zhao et al., 2023;\\nZhang et al., 2023), can complicate the communication topology, resulting in inefficiencies.\\nTo address this challenge, a viable approach is to store information in a global message pool. As\\nshown in Figure 2 (left), we introduce a shared message pool that allows all agents to exchange\\nmessages directly. These agents not onlypublish their structured messages in the pool but also access\\nmessages from other entities transparently. Any agent can directly retrieve required information\\nfrom the shared pool, eliminating the need to inquire about other agents and await their responses.\\nThis enhances communication efficiency.\\nSharing all information with every agent can lead to information overload. During task execution,\\nan agent typically prefers to receive only task-related information and avoid distractions through\\nirrelevant details. Effective management and dissemination of this information play a crucial role.\\nWe offer a simple and effective solution- subscription mechanism (in Figure 2 (left)). Instead of\\nrelying on dialogue, agents utilize role-specific interests to extract relevant information. They can\\nselect information to follow based on their role profiles. In practical implementations, an agent\\nactivates its action only after receiving all its prerequisite dependencies. As illustrated in Figure 3,\\nthe Architect mainly focuses on PRDs provided by the Product Manager, while documents from\\nroles such as the QA Engineer might be of lesser concern.\\n3.3 I TERATIVE PROGRAMMING WITH EXECUTABLE FEEDBACK\\nIn daily programming tasks, the processes of debugging and optimization play important roles.\\nHowever, existing methods often lack a self-correction mechanism, which leads to unsuccessful code\\ngeneration. Previous work introduced non-executable code review and self-reflection (Zhao et al.,\\n2023; Yao et al., 2022; Shinn et al., 2023; Dong et al., 2023). However, they still face challenges in\\nensuring code executability and runtime correctness.\\nOur first MetaGPT implementations overlooked certain errors during the review process, due to\\nLLM hallucinations (Manakul et al., 2023). To overcome this, after initial code generation, we\\nintroduce an executable feedback mechanism to improve the code iteratively. More specifically, as\\nshown in Figure 2, the Engineer is asked to write code based on the original product requirements\\nand design.\\nThis enables the Engineer to continuously improve code using its own historical execution and\\ndebugging memory. To obtain additional information, the Engineer writes and executes the corre-\\nsponding unit test cases, and subsequently receives the test results. If satisfactory, additional devel-\\nopment tasks are initiated. Otherwise the Engineer debugs the code before resuming programming.\\nThis iterative testing process continues until the test is passed or a maximum of 3 retries is reached.\\n4 E XPERIMENTS\\n4.1 E XPERIMENTAL SETTING\\nDatasets We use two public benchmarks, HumanEval (Chen et al., 2021a) and MBPP (Austin\\net al., 2021), and a self-generated, more challenging software development benchmark named Soft-\\n2https://en.wikipedia.org/wiki/Chinese whispers\\n6', mimetype='text/plain', start_char_idx=0, end_char_idx=4278, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.8117229344770936),\n",
       " NodeWithScore(node=TextNode(id_='2d59d9e5-249d-4a7a-be50-2e05d6be295a', embedding=None, metadata={'page_label': '11', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2025-04-30', 'last_modified_date': '2025-04-30'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='c0a07832-e697-45cd-ab2e-50da20305c0c', node_type='4', metadata={'page_label': '11', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2025-04-30', 'last_modified_date': '2025-04-30'}, hash='0cab6753e59392088532d59505348b371ccf8640b78dd3aa4804185a14002c3b'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='07cb1cd1-3cb2-467c-8e03-272be736108f', node_type='1', metadata={}, hash='f8e4cbc75bea3bb21000dfa4bcc33aeeecd0d9cbc4c7828c1fbd95d5f7a2cc73')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Preprint\\nWeize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chen Qian, Chi-Min Chan,\\nYujia Qin, Yaxi Lu, Ruobing Xie, Zhiyuan Liu, Maosong Sun, and Jie Zhou. Agentverse: Facili-\\ntating multi-agent collaboration and exploring emergent behaviors in agents, 2023.\\nXinyun Chen, Chang Liu, and Dawn Song. Execution-guided neural program synthesis. In ICLR,\\n2018.\\nXinyun Chen, Dawn Song, and Yuandong Tian. Latent execution for neural program synthesis\\nbeyond domain-specific languages. NeurIPS, 2021b.\\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam\\nRoberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh,\\nKensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam\\nShazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James\\nBradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Lev-\\nskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin\\nRobinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret\\nZoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick,\\nAndrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica\\nMoreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Bren-\\nnan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas\\nEck, Jeff Dean, Slav Petrov, and Noah Fiedel. Palm: Scaling language modeling with pathways,\\n2022.\\nT. DeMarco and T.R. Lister. Peopleware: Productive Projects and Teams. Addison-Wesley, 2013.\\nURL https://books.google.co.uk/books?id=DVlsAQAAQBAJ.\\nYihong Dong, Xue Jiang, Zhi Jin, and Ge Li. Self-collaboration code generation via chatgpt. arXiv\\npreprint, 2023.\\nYilun Du, Shuang Li, Antonio Torralba, Joshua B. Tenenbaum, and Igor Mordatch. Improving\\nfactuality and reasoning in language models through multiagent debate, 2023.\\nYanai Elazar, Nora Kassner, Shauli Ravfogel, Abhilasha Ravichander, Eduard Hovy, Hinrich\\nSch¨utze, and Yoav Goldberg. Measuring and improving consistency in pretrained language mod-\\nels. TACL, 2021.\\nZhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong, Linjun Shou, Bing\\nQin, Ting Liu, Daxin Jiang, et al. Codebert: A pre-trained model for programming and natural\\nlanguages. arXiv preprint, 2020.\\nChrisantha Fernando, Dylan Banarse, Henryk Michalewski, Simon Osindero, and Tim Rockt¨aschel.\\nPromptbreeder: Self-referential self-improvement via prompt evolution. arXiv preprint, 2023.\\nChelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation\\nof deep networks. In ICML, 2017.\\nDaniel Fried, Armen Aghajanyan, Jessy Lin, Sida Wang, Eric Wallace, Freda Shi, Ruiqi Zhong,\\nWen-tau Yih, Luke Zettlemoyer, and Mike Lewis. Incoder: A generative model for code infilling\\nand synthesis. arXiv preprint, 2022.\\nIrving John Good. Speculations concerning the first ultraintelligent machine. Adv. Comput., 1965.\\nRui Hao, Linmei Hu, Weijian Qi, Qingliu Wu, Yirui Zhang, and Liqiang Nie.', mimetype='text/plain', start_char_idx=0, end_char_idx=3139, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.797866885084047)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.source_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d639075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 1: The question asks about ablation study results, which are specific details that would be found in the MetaGPT paper..\n",
      "\u001b[0m<think>\n",
      "Okay, so I need to figure out how to answer the query about the ablation study results based on the provided context. Let me start by understanding what an ablation study is. From what I remember, an ablation study is a method used in machine learning to determine the contribution of different components or parameters in a model. It helps identify which parts are essential and how their removal affects the model's performance.\n",
      "\n",
      "Looking at the context information, I see a list of references from various papers. I need to find any mention of ablation studies or their results. I'll go through each entry one by one.\n",
      "\n",
      "Starting from the top, the first few papers are about communicative agents, code generation, and multi-agent debates. I don't see any direct mention of ablation studies here. Moving on, there's a paper by Bill Yuchen Lin et al. titled \"Swiftsage: A generative agent with fast and slow thinking for complex interactive tasks.\" This might involve some analysis of different thinking mechanisms, but I'm not sure if it includes ablation studies.\n",
      "\n",
      "Next, Ruibo Liu et al.'s paper is about training socially aligned language models. This could involve testing different training parameters, which might include ablation studies to see how each component affects social alignment. However, without the full text, I can't confirm.\n",
      "\n",
      "Looking further down, there's a paper by Ziyang Luo et al. titled \"Wizardcoder: Empowering code large language models with evol-instruct.\" This might discuss how different instructional methods impact model performance, possibly through ablation.\n",
      "\n",
      "Then, Potsawee Manakul et al.'s paper on \"Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models.\" This seems relevant because detecting hallucinations might involve testing various detection methods, which could include ablation studies to identify the most effective components.\n",
      "\n",
      "Continuing, there's a paper by Ansong Ni et al. titled \"Lever: Learning to verify language-to-code generation with execution.\" This could involve ablation studies to test the effectiveness of different verification methods.\n",
      "\n",
      "Erik Nijkamp et al.'s \"Codegen: An open large language model for code with multi-turn program synthesis\" might include ablation studies on different synthesis approaches.\n",
      "\n",
      "Joon Sung Park et al.'s paper on \"Generative agents: Interactive simulacra of human behavior\" could involve testing various interactive components, possibly through ablation.\n",
      "\n",
      "Chen Qian et al.'s work on \"Communicative agents for software development\" might include studies on how different communication strategies affect performance.\n",
      "\n",
      "Baptiste Rozière et al.'s \"Code llama: Open foundation models for code\" could have ablation studies on model architecture components.\n",
      "\n",
      "Timo Schick et al.'s \"Toolformer: Language models can teach themselves to use tools\" might involve ablation to determine which tools or components are most essential.\n",
      "\n",
      "J. Schmidhuber's work on \"Gödel machines: self-referential universal problem solvers\" is more theoretical but could involve ablation in testing self-improvement mechanisms.\n",
      "\n",
      "On page 14, Hongxin Zhang et al.'s paper on cooperative embodied agents might include ablation studies on cooperation mechanisms. Xufeng Zhao et al.'s work on interactive multimodal perception could involve testing different modalities through ablation.\n",
      "\n",
      "Qinkai Zheng et al.'s \"Codegeex\" might have ablation studies on code generation methods. Shuyan Zhou et al.'s \"Webarena\" could involve testing different environmental interactions. Mingchen Zhuge et al.'s \"Mindstorms\" might include ablation on societal models.\n",
      "\n",
      "Overall, while several papers might include ablation studies, without specific details from each, I can't provide exact results. However, I can infer that ablation studies in these contexts likely tested components like different model architectures, training parameters, interaction methods, and tool usage, aiming to identify which elements are crucial for performance.\n",
      "</think>\n",
      "\n",
      "The ablation study results from the context suggest that various components were tested across different models and systems. These studies likely examined the impact of removing specific elements such as model architectures, training parameters, interaction methods, and tool usage. The findings would highlight which components are essential for maintaining or improving performance in areas like code generation, social alignment, hallucination detection, and interactive agents. Each study would have identified key factors contributing to the model's effectiveness, providing insights into optimal configurations and necessary elements for desired outcomes.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Tell me about the ablation study results?\")\n",
    "print(str(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
